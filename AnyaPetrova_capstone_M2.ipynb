{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2LYZ73exh6r"
   },
   "source": [
    "# Capstone Project Milestone 2 #\n",
    "## Anya Petrova ##\n",
    "\n",
    "**Please use this template to add your code and text content on top of it **  \n",
    "**You may modify this tempalte to fit your need but try to keep the content order as listed **\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cb9hTOKoGj_"
   },
   "source": [
    "**1. Save a copy tempalte to your own Google drive so you can edit and put in your own result**    \n",
    "**2. Save the final work in the form of yourname_capstoneM2.ipynb on your Google drive and**  \n",
    "**3. Share your ipynb file with ** ***mark.popovich@generalassemb.ly***  \n",
    "**4. Make sure you code run well under Google Colab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEVsFkTDxh6t"
   },
   "source": [
    "* * *\n",
    "**Clearly document and label each section**\n",
    "\n",
    "* Logically organize your information in a persuasive, informative manner\n",
    "* Include notebook headers and subheaders, as well as clearly formatted markdown for all written components\n",
    "* Include graphs/plots/visualizations with clear labels\n",
    "* Comment and explain the purpose of each major section/subsection of your code\n",
    "* Document your code for your future self, as if another person needed to replicate your approach\n",
    "* For any given step, consider the logic that links it to other steps and clearly describe each assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf47w1tAo12K"
   },
   "source": [
    "###Assemble an EDA notebook for your dataset###\n",
    "* It should be written in a straightforward manner, with concisely commented code, documented procedures and reasoning, and logical analysis. \n",
    "* Where applicable, include clearly labeled plots, graphs, and other visualizations, explaining any outliers and relationships between features and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyOPeTpKbmbK"
   },
   "source": [
    "#Executive Summary#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRBuDPsnbyQU"
   },
   "source": [
    "##What is your goal?##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T21xbJ1Sb41l"
   },
   "source": [
    "The goal is to built a matchmaking service for people to find friends based on book interrests. \n",
    "The idea is to be able to set up your profile by simply uploading a photo of your bookshelf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQzfYtUBcDh-"
   },
   "source": [
    "##What are your metrics?##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZNb1WU1cG1V"
   },
   "source": [
    "The project is broken into 3 distinct parts and each has its own approach to metrics:  \n",
    "\n",
    "1. Extracting book information from photos \n",
    "\n",
    "    - here, the key metrics is a recall and precition of extraction of of information from photos, that is \"out of books on the photo, how many have we identified correctly\" (recall) & \"out of books we've identified, how many are correct titles\" (precision)\n",
    "    \n",
    "    \n",
    "2. Setting up user's profile of interrests based on extracted information\n",
    "\n",
    "    - here, the goal is to cluster books we have identified into some categories (fiction, romance, etc. ); however, we do not want to predetermine any category sets, so what we will be doing here is an unsupervised learning; I would like our system to define clusters and \"label\" them with a cloud of most common terms. For example, my personal bookshelf would contain a cluster with a word cloud: \"AI, Futurism, Life Extension, Mars.. etc.\" and another cluster with a word cloud like: \"Proggramming, algorythms, computer, python, data, etc..\"\n",
    "    \n",
    "    - I'm not sure what kind of a success metrics would be applicable here as this is an unsupervised learning and we don't have any predefined labels. \n",
    "    \n",
    "    \n",
    "3. Matchmaking users\n",
    "\n",
    "    - Finally, we need to create matches. I am still working on this part and designing the approach, however, once again, I do not think we could have a simple and straightforward metrics here as the quality of matchmaking is partially a subjective assesment. What I would love to see is simply that people with simmilar interrest have higher simmilarity index. However, in the future and If I were to turn this project into a live service I can see how implementing other, more sophisticated techniques would be appropriate; For example, we might want to try to matchmake people who have overlapping interrests, but each party has a strong interrest in a subject/topic/author that we would predict would be of an interrest to their \"match\" and vice versa. The assumption here is that once there people make contact they have some interesting topings that they woudl love to be able to exchange, not just regurgitate on things they both are already very fammiliiar with.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtgzNBavcK0W"
   },
   "source": [
    "##What were your findings?##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JSHdbCEcRjZ"
   },
   "source": [
    "Well, I don't have any particular findings about the data, however, as far as the proccess, I've discovered:\n",
    "\n",
    "    - It is much easier to approach the extraction of text from image by simply using a pytesseract library then inventing my own CNN network. (Originally I started trying to detect books, via detecting edges, parallell lines, etc. using OpenCV.) However, I came up with a much more efficient hack, which is outlined in the code below. \n",
    "    \n",
    "    - I've discovered that Amazon is using two absolutely different templates for all theis product pages and rotate them every day. I had to write two different versions of scrapers :)\n",
    "    \n",
    "    - Google will start testing if I am a robot if I am doing too many auto-searches. Eventually, in the production enviroment I will need to figure out different ways of identifying and confirming book titles then performing Google/Amazon scrape...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x3qbU2DKcUMR"
   },
   "source": [
    "##What risks/limitations/assumptions affect these findings?##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEM2E2MdcYlB"
   },
   "source": [
    "    - I think that my biggest assumption is that matchmaking people based on common interrest identified in their book reading lists would produce good quality of matches (that is people will like each other, could be friends and will have things to talk/exchange about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSJzQoRlxh6v"
   },
   "source": [
    "## Step 1: Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nlGZKhg1pXJ2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-93362013aeca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Code to read csv file into colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HqqNA_CCpZnr"
   },
   "outputs": [],
   "source": [
    "#2. Get the file \n",
    "# modify the following as needed\n",
    "# make sure you upload all your data files to your Google drive and\n",
    "# change the file privilege by share->Advanced->change->anyone with the link can view\n",
    "downloaded = drive.CreateFile({'id':'12HU5u2VsnWc6xKdz8EQQYQxEWTh6xZyR'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('train.csv') \n",
    "downloaded = drive.CreateFile({'id':'1M-Ag3cLveRHKYN0bO4oUGAcPumemoGBy'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('test.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11EaY3sdxh64"
   },
   "source": [
    "### More here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wYqpyeL0xh65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOkmwCllxh68"
   },
   "source": [
    "## Step 2: statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NmhdmHqxh68"
   },
   "source": [
    "### Implementation ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KDoPcpDnMcHd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IdHsLdgxh7F"
   },
   "source": [
    "## evaluation ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AuicWROKxh7G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_NbBzbGdFBp"
   },
   "source": [
    "##inference##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vKWDatwEdKoy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nIzrQiJQxh7X"
   },
   "source": [
    "## 3: technical appendix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgxOuTW2xh7Y"
   },
   "source": [
    "Links and explanations to any outside libraries or source code used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY4-HG9Hxh7c"
   },
   "source": [
    "More here\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "capstone_M2_template.ipynb",
   "provenance": [
    {
     "file_id": "1x5WzsOZU75qNBM2HaC-IdMaGOjAOJg9r",
     "timestamp": 1518650782969
    },
    {
     "file_id": "19pfSZyLw9OkkHDyvf3VYAnqg1U9GMJRA",
     "timestamp": 1518557285814
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
